{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import sys\n",
    "from imp import reload\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "if sys.version[0] == '2':\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aliqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aliqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import datetime\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  With all this stuff going down at the moment w...\n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2          0  The film starts with a manager (Nicholas Bell)...\n",
       "3          0  It must be assumed that those who praised this...\n",
       "4          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"D:/DataRepository/final_project/Final-Project-IMDB-Reviews/labeledTrainData.tsv\"\n",
    "\n",
    "# Import the CSV into a pandas DataFrame\n",
    "df = pd.read_csv(csv_path, low_memory=False, sep = '\\t')\n",
    "df = df.drop(['id'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  With all this stuff going down at the moment w...          1\n",
       "1  \\The Classic War of the Worlds\\\" by Timothy Hi...          1\n",
       "2  The film starts with a manager (Nicholas Bell)...          0\n",
       "3  It must be assumed that those who praised this...          0\n",
       "4  Superbly trashy and wondrously unpretentious 8...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = df[['review','sentiment']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# stop_words = set(stopwords.words(\"english\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\")) \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
    "    text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "    text = [word for word in text if not word in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "df['Processed_Reviews'] = df.review.apply(lambda x: clean_text(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Processed_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>1</td>\n",
       "      <td>stuff go moment mj ive start listen music watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>classic war world timothy hines entertain film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>0</td>\n",
       "      <td>film start manager nicholas bell give welcome ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>0</td>\n",
       "      <td>must assume praise film greatest film opera ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>1</td>\n",
       "      <td>superbly trashy wondrously unpretentious 80 ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  With all this stuff going down at the moment w...          1   \n",
       "1  \\The Classic War of the Worlds\\\" by Timothy Hi...          1   \n",
       "2  The film starts with a manager (Nicholas Bell)...          0   \n",
       "3  It must be assumed that those who praised this...          0   \n",
       "4  Superbly trashy and wondrously unpretentious 8...          1   \n",
       "\n",
       "                                   Processed_Reviews  \n",
       "0  stuff go moment mj ive start listen music watc...  \n",
       "1  classic war world timothy hines entertain film...  \n",
       "2  film start manager nicholas bell give welcome ...  \n",
       "3  must assume praise film greatest film opera ev...  \n",
       "4  superbly trashy wondrously unpretentious 80 ex...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129.54916"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Processed_Reviews.apply(lambda x: len(x.split(\" \"))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 6000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(df['Processed_Reviews'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(df['Processed_Reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 130\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aliqu\\AppData\\Local\\Continuum\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\aliqu\\AppData\\Local\\Continuum\\anaconda3\\envs\\py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\aliqu\\AppData\\Local\\Continuum\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\aliqu\\AppData\\Local\\Continuum\\anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - ETA: 8:14 - loss: 0.6942 - acc: 0.460 - ETA: 4:35 - loss: 0.6939 - acc: 0.475 - ETA: 3:18 - loss: 0.6935 - acc: 0.490 - ETA: 2:37 - loss: 0.6935 - acc: 0.490 - ETA: 2:12 - loss: 0.6932 - acc: 0.492 - ETA: 1:55 - loss: 0.6934 - acc: 0.491 - ETA: 1:43 - loss: 0.6934 - acc: 0.491 - ETA: 1:34 - loss: 0.6931 - acc: 0.497 - ETA: 1:27 - loss: 0.6930 - acc: 0.500 - ETA: 1:21 - loss: 0.6930 - acc: 0.500 - ETA: 1:17 - loss: 0.6926 - acc: 0.506 - ETA: 1:13 - loss: 0.6925 - acc: 0.506 - ETA: 1:09 - loss: 0.6923 - acc: 0.508 - ETA: 1:07 - loss: 0.6925 - acc: 0.502 - ETA: 1:04 - loss: 0.6925 - acc: 0.500 - ETA: 1:02 - loss: 0.6926 - acc: 0.495 - ETA: 1:00 - loss: 0.6926 - acc: 0.493 - ETA: 58s - loss: 0.6924 - acc: 0.496 - ETA: 56s - loss: 0.6923 - acc: 0.50 - ETA: 55s - loss: 0.6921 - acc: 0.51 - ETA: 54s - loss: 0.6919 - acc: 0.51 - ETA: 52s - loss: 0.6917 - acc: 0.52 - ETA: 51s - loss: 0.6916 - acc: 0.53 - ETA: 50s - loss: 0.6915 - acc: 0.54 - ETA: 50s - loss: 0.6913 - acc: 0.54 - ETA: 49s - loss: 0.6912 - acc: 0.54 - ETA: 48s - loss: 0.6910 - acc: 0.55 - ETA: 47s - loss: 0.6907 - acc: 0.56 - ETA: 46s - loss: 0.6905 - acc: 0.56 - ETA: 46s - loss: 0.6903 - acc: 0.57 - ETA: 46s - loss: 0.6901 - acc: 0.57 - ETA: 45s - loss: 0.6898 - acc: 0.58 - ETA: 45s - loss: 0.6894 - acc: 0.58 - ETA: 44s - loss: 0.6891 - acc: 0.58 - ETA: 43s - loss: 0.6889 - acc: 0.58 - ETA: 43s - loss: 0.6885 - acc: 0.59 - ETA: 42s - loss: 0.6882 - acc: 0.59 - ETA: 41s - loss: 0.6877 - acc: 0.60 - ETA: 41s - loss: 0.6872 - acc: 0.60 - ETA: 40s - loss: 0.6865 - acc: 0.61 - ETA: 40s - loss: 0.6858 - acc: 0.61 - ETA: 39s - loss: 0.6851 - acc: 0.62 - ETA: 39s - loss: 0.6841 - acc: 0.62 - ETA: 38s - loss: 0.6830 - acc: 0.62 - ETA: 38s - loss: 0.6819 - acc: 0.63 - ETA: 37s - loss: 0.6808 - acc: 0.63 - ETA: 37s - loss: 0.6795 - acc: 0.63 - ETA: 37s - loss: 0.6777 - acc: 0.64 - ETA: 36s - loss: 0.6753 - acc: 0.64 - ETA: 36s - loss: 0.6731 - acc: 0.65 - ETA: 35s - loss: 0.6709 - acc: 0.65 - ETA: 35s - loss: 0.6685 - acc: 0.65 - ETA: 35s - loss: 0.6654 - acc: 0.65 - ETA: 34s - loss: 0.6621 - acc: 0.66 - ETA: 34s - loss: 0.6576 - acc: 0.66 - ETA: 34s - loss: 0.6550 - acc: 0.66 - ETA: 34s - loss: 0.6530 - acc: 0.66 - ETA: 33s - loss: 0.6500 - acc: 0.67 - ETA: 33s - loss: 0.6470 - acc: 0.67 - ETA: 33s - loss: 0.6443 - acc: 0.67 - ETA: 32s - loss: 0.6435 - acc: 0.67 - ETA: 32s - loss: 0.6416 - acc: 0.67 - ETA: 32s - loss: 0.6385 - acc: 0.67 - ETA: 31s - loss: 0.6348 - acc: 0.68 - ETA: 31s - loss: 0.6321 - acc: 0.68 - ETA: 31s - loss: 0.6313 - acc: 0.68 - ETA: 30s - loss: 0.6289 - acc: 0.68 - ETA: 30s - loss: 0.6268 - acc: 0.68 - ETA: 30s - loss: 0.6250 - acc: 0.68 - ETA: 30s - loss: 0.6222 - acc: 0.68 - ETA: 29s - loss: 0.6203 - acc: 0.68 - ETA: 29s - loss: 0.6178 - acc: 0.69 - ETA: 29s - loss: 0.6151 - acc: 0.69 - ETA: 29s - loss: 0.6126 - acc: 0.69 - ETA: 28s - loss: 0.6099 - acc: 0.69 - ETA: 28s - loss: 0.6066 - acc: 0.69 - ETA: 28s - loss: 0.6043 - acc: 0.69 - ETA: 27s - loss: 0.6032 - acc: 0.70 - ETA: 27s - loss: 0.6004 - acc: 0.70 - ETA: 27s - loss: 0.5993 - acc: 0.70 - ETA: 27s - loss: 0.5963 - acc: 0.70 - ETA: 27s - loss: 0.5933 - acc: 0.70 - ETA: 27s - loss: 0.5924 - acc: 0.70 - ETA: 27s - loss: 0.5912 - acc: 0.70 - ETA: 26s - loss: 0.5896 - acc: 0.70 - ETA: 26s - loss: 0.5870 - acc: 0.70 - ETA: 26s - loss: 0.5848 - acc: 0.71 - ETA: 26s - loss: 0.5825 - acc: 0.71 - ETA: 25s - loss: 0.5807 - acc: 0.71 - ETA: 25s - loss: 0.5797 - acc: 0.71 - ETA: 25s - loss: 0.5791 - acc: 0.71 - ETA: 24s - loss: 0.5778 - acc: 0.71 - ETA: 24s - loss: 0.5766 - acc: 0.71 - ETA: 24s - loss: 0.5745 - acc: 0.71 - ETA: 24s - loss: 0.5721 - acc: 0.71 - ETA: 23s - loss: 0.5711 - acc: 0.71 - ETA: 23s - loss: 0.5684 - acc: 0.72 - ETA: 23s - loss: 0.5661 - acc: 0.72 - ETA: 22s - loss: 0.5643 - acc: 0.72 - ETA: 22s - loss: 0.5623 - acc: 0.72 - ETA: 22s - loss: 0.5602 - acc: 0.72 - ETA: 22s - loss: 0.5585 - acc: 0.72 - ETA: 21s - loss: 0.5565 - acc: 0.72 - ETA: 21s - loss: 0.5553 - acc: 0.72 - ETA: 21s - loss: 0.5539 - acc: 0.73 - ETA: 20s - loss: 0.5527 - acc: 0.73 - ETA: 20s - loss: 0.5504 - acc: 0.73 - ETA: 20s - loss: 0.5497 - acc: 0.73 - ETA: 20s - loss: 0.5485 - acc: 0.73 - ETA: 20s - loss: 0.5463 - acc: 0.73 - ETA: 19s - loss: 0.5450 - acc: 0.73 - ETA: 19s - loss: 0.5435 - acc: 0.73 - ETA: 19s - loss: 0.5415 - acc: 0.73 - ETA: 19s - loss: 0.5400 - acc: 0.73 - ETA: 18s - loss: 0.5385 - acc: 0.73 - ETA: 18s - loss: 0.5373 - acc: 0.74 - ETA: 18s - loss: 0.5351 - acc: 0.74 - ETA: 18s - loss: 0.5330 - acc: 0.74 - ETA: 17s - loss: 0.5316 - acc: 0.74 - ETA: 17s - loss: 0.5306 - acc: 0.74 - ETA: 17s - loss: 0.5293 - acc: 0.74 - ETA: 17s - loss: 0.5277 - acc: 0.74 - ETA: 17s - loss: 0.5262 - acc: 0.74 - ETA: 16s - loss: 0.5249 - acc: 0.74 - ETA: 16s - loss: 0.5232 - acc: 0.74 - ETA: 16s - loss: 0.5218 - acc: 0.74 - ETA: 16s - loss: 0.5206 - acc: 0.74 - ETA: 15s - loss: 0.5187 - acc: 0.75 - ETA: 15s - loss: 0.5176 - acc: 0.75 - ETA: 15s - loss: 0.5160 - acc: 0.75 - ETA: 15s - loss: 0.5146 - acc: 0.75 - ETA: 14s - loss: 0.5137 - acc: 0.75 - ETA: 14s - loss: 0.5125 - acc: 0.75 - ETA: 14s - loss: 0.5109 - acc: 0.75 - ETA: 14s - loss: 0.5097 - acc: 0.75 - ETA: 13s - loss: 0.5087 - acc: 0.75 - ETA: 13s - loss: 0.5070 - acc: 0.75 - ETA: 13s - loss: 0.5057 - acc: 0.75 - ETA: 13s - loss: 0.5047 - acc: 0.75 - ETA: 13s - loss: 0.5026 - acc: 0.76 - ETA: 12s - loss: 0.5014 - acc: 0.76 - ETA: 12s - loss: 0.5008 - acc: 0.76 - ETA: 12s - loss: 0.4996 - acc: 0.76 - ETA: 12s - loss: 0.4985 - acc: 0.76 - ETA: 11s - loss: 0.4971 - acc: 0.76 - ETA: 11s - loss: 0.4964 - acc: 0.76 - ETA: 11s - loss: 0.4950 - acc: 0.76 - ETA: 11s - loss: 0.4944 - acc: 0.76 - ETA: 11s - loss: 0.4932 - acc: 0.76 - ETA: 10s - loss: 0.4917 - acc: 0.76 - ETA: 10s - loss: 0.4905 - acc: 0.76 - ETA: 10s - loss: 0.4892 - acc: 0.76 - ETA: 10s - loss: 0.4882 - acc: 0.76 - ETA: 9s - loss: 0.4865 - acc: 0.7697 - ETA: 9s - loss: 0.4859 - acc: 0.770 - ETA: 9s - loss: 0.4857 - acc: 0.770 - ETA: 9s - loss: 0.4849 - acc: 0.771 - ETA: 9s - loss: 0.4837 - acc: 0.771 - ETA: 8s - loss: 0.4828 - acc: 0.772 - ETA: 8s - loss: 0.4820 - acc: 0.772 - ETA: 8s - loss: 0.4805 - acc: 0.773 - ETA: 8s - loss: 0.4800 - acc: 0.774 - ETA: 7s - loss: 0.4793 - acc: 0.774 - ETA: 7s - loss: 0.4787 - acc: 0.774 - ETA: 7s - loss: 0.4776 - acc: 0.775 - ETA: 7s - loss: 0.4763 - acc: 0.775 - ETA: 7s - loss: 0.4752 - acc: 0.776 - ETA: 6s - loss: 0.4739 - acc: 0.777 - ETA: 6s - loss: 0.4729 - acc: 0.777 - ETA: 6s - loss: 0.4718 - acc: 0.778 - ETA: 6s - loss: 0.4706 - acc: 0.779 - ETA: 6s - loss: 0.4701 - acc: 0.779 - ETA: 5s - loss: 0.4690 - acc: 0.780 - ETA: 5s - loss: 0.4681 - acc: 0.780 - ETA: 5s - loss: 0.4678 - acc: 0.781 - ETA: 5s - loss: 0.4669 - acc: 0.781 - ETA: 4s - loss: 0.4666 - acc: 0.781 - ETA: 4s - loss: 0.4654 - acc: 0.782 - ETA: 4s - loss: 0.4641 - acc: 0.783 - ETA: 4s - loss: 0.4629 - acc: 0.784 - ETA: 4s - loss: 0.4621 - acc: 0.784 - ETA: 3s - loss: 0.4610 - acc: 0.785 - ETA: 3s - loss: 0.4603 - acc: 0.785 - ETA: 3s - loss: 0.4592 - acc: 0.786 - ETA: 3s - loss: 0.4585 - acc: 0.786 - ETA: 2s - loss: 0.4577 - acc: 0.786 - ETA: 2s - loss: 0.4570 - acc: 0.787 - ETA: 2s - loss: 0.4566 - acc: 0.787 - ETA: 2s - loss: 0.4557 - acc: 0.788 - ETA: 2s - loss: 0.4550 - acc: 0.788 - ETA: 1s - loss: 0.4537 - acc: 0.789 - ETA: 1s - loss: 0.4525 - acc: 0.789 - ETA: 1s - loss: 0.4515 - acc: 0.790 - ETA: 1s - loss: 0.4511 - acc: 0.790 - ETA: 1s - loss: 0.4509 - acc: 0.790 - ETA: 0s - loss: 0.4503 - acc: 0.791 - ETA: 0s - loss: 0.4497 - acc: 0.791 - ETA: 0s - loss: 0.4494 - acc: 0.791 - ETA: 0s - loss: 0.4486 - acc: 0.792 - 45s 2ms/step - loss: 0.4472 - acc: 0.7930 - val_loss: 0.3161 - val_acc: 0.8674\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - ETA: 39s - loss: 0.2593 - acc: 0.92 - ETA: 37s - loss: 0.2737 - acc: 0.89 - ETA: 37s - loss: 0.2659 - acc: 0.89 - ETA: 36s - loss: 0.2683 - acc: 0.90 - ETA: 40s - loss: 0.2657 - acc: 0.90 - ETA: 42s - loss: 0.2560 - acc: 0.90 - ETA: 41s - loss: 0.2557 - acc: 0.90 - ETA: 40s - loss: 0.2523 - acc: 0.90 - ETA: 40s - loss: 0.2519 - acc: 0.91 - ETA: 39s - loss: 0.2570 - acc: 0.90 - ETA: 39s - loss: 0.2542 - acc: 0.90 - ETA: 38s - loss: 0.2623 - acc: 0.90 - ETA: 38s - loss: 0.2609 - acc: 0.90 - ETA: 37s - loss: 0.2575 - acc: 0.90 - ETA: 37s - loss: 0.2581 - acc: 0.90 - ETA: 36s - loss: 0.2530 - acc: 0.90 - ETA: 36s - loss: 0.2550 - acc: 0.90 - ETA: 35s - loss: 0.2540 - acc: 0.90 - ETA: 35s - loss: 0.2496 - acc: 0.91 - ETA: 35s - loss: 0.2450 - acc: 0.91 - ETA: 35s - loss: 0.2468 - acc: 0.91 - ETA: 34s - loss: 0.2424 - acc: 0.91 - ETA: 34s - loss: 0.2452 - acc: 0.91 - ETA: 34s - loss: 0.2466 - acc: 0.91 - ETA: 33s - loss: 0.2457 - acc: 0.91 - ETA: 33s - loss: 0.2495 - acc: 0.90 - ETA: 33s - loss: 0.2504 - acc: 0.90 - ETA: 32s - loss: 0.2484 - acc: 0.91 - ETA: 32s - loss: 0.2468 - acc: 0.91 - ETA: 32s - loss: 0.2477 - acc: 0.91 - ETA: 32s - loss: 0.2479 - acc: 0.91 - ETA: 31s - loss: 0.2467 - acc: 0.91 - ETA: 31s - loss: 0.2464 - acc: 0.91 - ETA: 32s - loss: 0.2438 - acc: 0.91 - ETA: 31s - loss: 0.2428 - acc: 0.91 - ETA: 31s - loss: 0.2447 - acc: 0.91 - ETA: 31s - loss: 0.2466 - acc: 0.91 - ETA: 31s - loss: 0.2481 - acc: 0.90 - ETA: 30s - loss: 0.2472 - acc: 0.91 - ETA: 30s - loss: 0.2468 - acc: 0.91 - ETA: 30s - loss: 0.2484 - acc: 0.90 - ETA: 30s - loss: 0.2469 - acc: 0.90 - ETA: 29s - loss: 0.2452 - acc: 0.91 - ETA: 29s - loss: 0.2439 - acc: 0.91 - ETA: 29s - loss: 0.2450 - acc: 0.91 - ETA: 29s - loss: 0.2449 - acc: 0.91 - ETA: 29s - loss: 0.2442 - acc: 0.91 - ETA: 28s - loss: 0.2440 - acc: 0.91 - ETA: 28s - loss: 0.2437 - acc: 0.91 - ETA: 28s - loss: 0.2427 - acc: 0.91 - ETA: 28s - loss: 0.2430 - acc: 0.91 - ETA: 27s - loss: 0.2420 - acc: 0.91 - ETA: 27s - loss: 0.2434 - acc: 0.91 - ETA: 27s - loss: 0.2436 - acc: 0.90 - ETA: 27s - loss: 0.2437 - acc: 0.90 - ETA: 27s - loss: 0.2437 - acc: 0.90 - ETA: 26s - loss: 0.2437 - acc: 0.90 - ETA: 26s - loss: 0.2428 - acc: 0.90 - ETA: 26s - loss: 0.2433 - acc: 0.90 - ETA: 26s - loss: 0.2441 - acc: 0.90 - ETA: 26s - loss: 0.2433 - acc: 0.90 - ETA: 25s - loss: 0.2445 - acc: 0.90 - ETA: 26s - loss: 0.2445 - acc: 0.90 - ETA: 25s - loss: 0.2453 - acc: 0.90 - ETA: 25s - loss: 0.2460 - acc: 0.90 - ETA: 25s - loss: 0.2471 - acc: 0.90 - ETA: 25s - loss: 0.2491 - acc: 0.90 - ETA: 25s - loss: 0.2491 - acc: 0.90 - ETA: 25s - loss: 0.2483 - acc: 0.90 - ETA: 25s - loss: 0.2484 - acc: 0.90 - ETA: 25s - loss: 0.2476 - acc: 0.90 - ETA: 24s - loss: 0.2470 - acc: 0.90 - ETA: 24s - loss: 0.2479 - acc: 0.90 - ETA: 24s - loss: 0.2479 - acc: 0.90 - ETA: 24s - loss: 0.2473 - acc: 0.90 - ETA: 24s - loss: 0.2471 - acc: 0.90 - ETA: 24s - loss: 0.2470 - acc: 0.90 - ETA: 23s - loss: 0.2478 - acc: 0.90 - ETA: 23s - loss: 0.2484 - acc: 0.90 - ETA: 23s - loss: 0.2478 - acc: 0.90 - ETA: 23s - loss: 0.2481 - acc: 0.90 - ETA: 23s - loss: 0.2496 - acc: 0.90 - ETA: 22s - loss: 0.2495 - acc: 0.90 - ETA: 22s - loss: 0.2489 - acc: 0.90 - ETA: 22s - loss: 0.2488 - acc: 0.90 - ETA: 22s - loss: 0.2489 - acc: 0.90 - ETA: 22s - loss: 0.2480 - acc: 0.90 - ETA: 22s - loss: 0.2485 - acc: 0.90 - ETA: 22s - loss: 0.2484 - acc: 0.90 - ETA: 21s - loss: 0.2481 - acc: 0.90 - ETA: 21s - loss: 0.2475 - acc: 0.90 - ETA: 21s - loss: 0.2468 - acc: 0.90 - ETA: 21s - loss: 0.2468 - acc: 0.90 - ETA: 21s - loss: 0.2484 - acc: 0.90 - ETA: 20s - loss: 0.2484 - acc: 0.90 - ETA: 20s - loss: 0.2474 - acc: 0.90 - ETA: 20s - loss: 0.2465 - acc: 0.90 - ETA: 20s - loss: 0.2467 - acc: 0.90 - ETA: 20s - loss: 0.2467 - acc: 0.90 - ETA: 19s - loss: 0.2458 - acc: 0.90 - ETA: 19s - loss: 0.2466 - acc: 0.90 - ETA: 19s - loss: 0.2467 - acc: 0.90 - ETA: 19s - loss: 0.2470 - acc: 0.90 - ETA: 19s - loss: 0.2478 - acc: 0.90 - ETA: 18s - loss: 0.2481 - acc: 0.90 - ETA: 18s - loss: 0.2482 - acc: 0.90 - ETA: 18s - loss: 0.2476 - acc: 0.90 - ETA: 18s - loss: 0.2479 - acc: 0.90 - ETA: 18s - loss: 0.2475 - acc: 0.90 - ETA: 17s - loss: 0.2483 - acc: 0.90 - ETA: 17s - loss: 0.2486 - acc: 0.90 - ETA: 17s - loss: 0.2485 - acc: 0.90 - ETA: 17s - loss: 0.2483 - acc: 0.90 - ETA: 17s - loss: 0.2481 - acc: 0.90 - ETA: 16s - loss: 0.2489 - acc: 0.90 - ETA: 16s - loss: 0.2487 - acc: 0.90 - ETA: 16s - loss: 0.2481 - acc: 0.90 - ETA: 16s - loss: 0.2484 - acc: 0.90 - ETA: 16s - loss: 0.2485 - acc: 0.90 - ETA: 15s - loss: 0.2482 - acc: 0.90 - ETA: 15s - loss: 0.2488 - acc: 0.90 - ETA: 15s - loss: 0.2493 - acc: 0.90 - ETA: 15s - loss: 0.2492 - acc: 0.90 - ETA: 15s - loss: 0.2488 - acc: 0.90 - ETA: 14s - loss: 0.2488 - acc: 0.90 - ETA: 14s - loss: 0.2490 - acc: 0.90 - ETA: 14s - loss: 0.2486 - acc: 0.90 - ETA: 14s - loss: 0.2486 - acc: 0.90 - ETA: 13s - loss: 0.2488 - acc: 0.90 - ETA: 13s - loss: 0.2489 - acc: 0.90 - ETA: 13s - loss: 0.2490 - acc: 0.90 - ETA: 13s - loss: 0.2488 - acc: 0.90 - ETA: 13s - loss: 0.2492 - acc: 0.90 - ETA: 13s - loss: 0.2494 - acc: 0.90 - ETA: 12s - loss: 0.2498 - acc: 0.90 - ETA: 12s - loss: 0.2494 - acc: 0.90 - ETA: 12s - loss: 0.2494 - acc: 0.90 - ETA: 12s - loss: 0.2492 - acc: 0.90 - ETA: 12s - loss: 0.2488 - acc: 0.90 - ETA: 11s - loss: 0.2487 - acc: 0.90 - ETA: 11s - loss: 0.2485 - acc: 0.90 - ETA: 11s - loss: 0.2490 - acc: 0.90 - ETA: 11s - loss: 0.2490 - acc: 0.90 - ETA: 11s - loss: 0.2487 - acc: 0.90 - ETA: 10s - loss: 0.2481 - acc: 0.90 - ETA: 10s - loss: 0.2478 - acc: 0.90 - ETA: 10s - loss: 0.2474 - acc: 0.90 - ETA: 10s - loss: 0.2470 - acc: 0.90 - ETA: 10s - loss: 0.2468 - acc: 0.90 - ETA: 9s - loss: 0.2471 - acc: 0.9057 - ETA: 9s - loss: 0.2464 - acc: 0.905 - ETA: 9s - loss: 0.2457 - acc: 0.906 - ETA: 9s - loss: 0.2449 - acc: 0.906 - ETA: 9s - loss: 0.2449 - acc: 0.906 - ETA: 8s - loss: 0.2450 - acc: 0.906 - ETA: 8s - loss: 0.2457 - acc: 0.906 - ETA: 8s - loss: 0.2459 - acc: 0.906 - ETA: 8s - loss: 0.2458 - acc: 0.906 - ETA: 8s - loss: 0.2452 - acc: 0.906 - ETA: 7s - loss: 0.2452 - acc: 0.906 - ETA: 7s - loss: 0.2452 - acc: 0.906 - ETA: 7s - loss: 0.2454 - acc: 0.906 - ETA: 7s - loss: 0.2454 - acc: 0.906 - ETA: 7s - loss: 0.2459 - acc: 0.905 - ETA: 6s - loss: 0.2462 - acc: 0.905 - ETA: 6s - loss: 0.2461 - acc: 0.905 - ETA: 6s - loss: 0.2462 - acc: 0.905 - ETA: 6s - loss: 0.2458 - acc: 0.905 - ETA: 6s - loss: 0.2460 - acc: 0.905 - ETA: 5s - loss: 0.2463 - acc: 0.905 - ETA: 5s - loss: 0.2459 - acc: 0.905 - ETA: 5s - loss: 0.2468 - acc: 0.905 - ETA: 5s - loss: 0.2469 - acc: 0.905 - ETA: 5s - loss: 0.2467 - acc: 0.905 - ETA: 4s - loss: 0.2472 - acc: 0.904 - ETA: 4s - loss: 0.2472 - acc: 0.904 - ETA: 4s - loss: 0.2468 - acc: 0.904 - ETA: 4s - loss: 0.2474 - acc: 0.904 - ETA: 4s - loss: 0.2475 - acc: 0.904 - ETA: 3s - loss: 0.2473 - acc: 0.904 - ETA: 3s - loss: 0.2468 - acc: 0.905 - ETA: 3s - loss: 0.2466 - acc: 0.905 - ETA: 3s - loss: 0.2466 - acc: 0.905 - ETA: 3s - loss: 0.2467 - acc: 0.904 - ETA: 2s - loss: 0.2468 - acc: 0.904 - ETA: 2s - loss: 0.2468 - acc: 0.904 - ETA: 2s - loss: 0.2465 - acc: 0.905 - ETA: 2s - loss: 0.2462 - acc: 0.905 - ETA: 2s - loss: 0.2465 - acc: 0.905 - ETA: 1s - loss: 0.2465 - acc: 0.905 - ETA: 1s - loss: 0.2464 - acc: 0.905 - ETA: 1s - loss: 0.2464 - acc: 0.905 - ETA: 1s - loss: 0.2460 - acc: 0.905 - ETA: 1s - loss: 0.2460 - acc: 0.905 - ETA: 0s - loss: 0.2457 - acc: 0.905 - ETA: 0s - loss: 0.2457 - acc: 0.905 - ETA: 0s - loss: 0.2459 - acc: 0.905 - ETA: 0s - loss: 0.2458 - acc: 0.905 - ETA: 0s - loss: 0.2456 - acc: 0.905 - 42s 2ms/step - loss: 0.2459 - acc: 0.9059 - val_loss: 0.3124 - val_acc: 0.8700\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - ETA: 36s - loss: 0.1685 - acc: 0.95 - ETA: 39s - loss: 0.1573 - acc: 0.95 - ETA: 37s - loss: 0.1419 - acc: 0.97 - ETA: 37s - loss: 0.1395 - acc: 0.96 - ETA: 36s - loss: 0.1521 - acc: 0.96 - ETA: 36s - loss: 0.1630 - acc: 0.95 - ETA: 36s - loss: 0.1677 - acc: 0.95 - ETA: 36s - loss: 0.1788 - acc: 0.94 - ETA: 35s - loss: 0.1779 - acc: 0.94 - ETA: 35s - loss: 0.1758 - acc: 0.94 - ETA: 35s - loss: 0.1732 - acc: 0.94 - ETA: 35s - loss: 0.1770 - acc: 0.94 - ETA: 35s - loss: 0.1754 - acc: 0.94 - ETA: 38s - loss: 0.1732 - acc: 0.94 - ETA: 38s - loss: 0.1793 - acc: 0.94 - ETA: 38s - loss: 0.1750 - acc: 0.94 - ETA: 37s - loss: 0.1729 - acc: 0.94 - ETA: 37s - loss: 0.1715 - acc: 0.94 - ETA: 36s - loss: 0.1718 - acc: 0.94 - ETA: 36s - loss: 0.1717 - acc: 0.94 - ETA: 35s - loss: 0.1711 - acc: 0.94 - ETA: 35s - loss: 0.1666 - acc: 0.94 - ETA: 35s - loss: 0.1649 - acc: 0.94 - ETA: 35s - loss: 0.1631 - acc: 0.94 - ETA: 34s - loss: 0.1658 - acc: 0.94 - ETA: 34s - loss: 0.1644 - acc: 0.94 - ETA: 34s - loss: 0.1635 - acc: 0.94 - ETA: 34s - loss: 0.1617 - acc: 0.94 - ETA: 33s - loss: 0.1603 - acc: 0.94 - ETA: 33s - loss: 0.1619 - acc: 0.94 - ETA: 33s - loss: 0.1628 - acc: 0.94 - ETA: 33s - loss: 0.1638 - acc: 0.94 - ETA: 32s - loss: 0.1651 - acc: 0.94 - ETA: 32s - loss: 0.1649 - acc: 0.94 - ETA: 32s - loss: 0.1641 - acc: 0.94 - ETA: 31s - loss: 0.1657 - acc: 0.94 - ETA: 31s - loss: 0.1674 - acc: 0.94 - ETA: 31s - loss: 0.1676 - acc: 0.94 - ETA: 31s - loss: 0.1676 - acc: 0.94 - ETA: 30s - loss: 0.1677 - acc: 0.94 - ETA: 30s - loss: 0.1665 - acc: 0.94 - ETA: 31s - loss: 0.1649 - acc: 0.94 - ETA: 31s - loss: 0.1656 - acc: 0.94 - ETA: 31s - loss: 0.1672 - acc: 0.94 - ETA: 30s - loss: 0.1664 - acc: 0.94 - ETA: 30s - loss: 0.1677 - acc: 0.94 - ETA: 30s - loss: 0.1682 - acc: 0.93 - ETA: 30s - loss: 0.1672 - acc: 0.94 - ETA: 30s - loss: 0.1668 - acc: 0.94 - ETA: 29s - loss: 0.1680 - acc: 0.93 - ETA: 29s - loss: 0.1686 - acc: 0.93 - ETA: 29s - loss: 0.1705 - acc: 0.93 - ETA: 29s - loss: 0.1708 - acc: 0.93 - ETA: 28s - loss: 0.1704 - acc: 0.93 - ETA: 28s - loss: 0.1709 - acc: 0.93 - ETA: 28s - loss: 0.1718 - acc: 0.93 - ETA: 28s - loss: 0.1716 - acc: 0.93 - ETA: 27s - loss: 0.1724 - acc: 0.93 - ETA: 27s - loss: 0.1722 - acc: 0.93 - ETA: 27s - loss: 0.1705 - acc: 0.93 - ETA: 27s - loss: 0.1727 - acc: 0.93 - ETA: 27s - loss: 0.1731 - acc: 0.93 - ETA: 26s - loss: 0.1719 - acc: 0.93 - ETA: 26s - loss: 0.1714 - acc: 0.93 - ETA: 26s - loss: 0.1717 - acc: 0.93 - ETA: 26s - loss: 0.1707 - acc: 0.93 - ETA: 25s - loss: 0.1705 - acc: 0.93 - ETA: 25s - loss: 0.1700 - acc: 0.93 - ETA: 25s - loss: 0.1706 - acc: 0.93 - ETA: 25s - loss: 0.1708 - acc: 0.93 - ETA: 25s - loss: 0.1709 - acc: 0.93 - ETA: 25s - loss: 0.1712 - acc: 0.93 - ETA: 25s - loss: 0.1722 - acc: 0.93 - ETA: 24s - loss: 0.1716 - acc: 0.93 - ETA: 24s - loss: 0.1716 - acc: 0.93 - ETA: 24s - loss: 0.1722 - acc: 0.93 - ETA: 24s - loss: 0.1722 - acc: 0.93 - ETA: 23s - loss: 0.1713 - acc: 0.93 - ETA: 23s - loss: 0.1702 - acc: 0.93 - ETA: 23s - loss: 0.1704 - acc: 0.93 - ETA: 23s - loss: 0.1709 - acc: 0.93 - ETA: 23s - loss: 0.1722 - acc: 0.93 - ETA: 22s - loss: 0.1724 - acc: 0.93 - ETA: 22s - loss: 0.1733 - acc: 0.93 - ETA: 22s - loss: 0.1745 - acc: 0.93 - ETA: 22s - loss: 0.1750 - acc: 0.93 - ETA: 22s - loss: 0.1749 - acc: 0.93 - ETA: 22s - loss: 0.1750 - acc: 0.93 - ETA: 21s - loss: 0.1744 - acc: 0.93 - ETA: 21s - loss: 0.1740 - acc: 0.93 - ETA: 21s - loss: 0.1743 - acc: 0.93 - ETA: 21s - loss: 0.1744 - acc: 0.93 - ETA: 21s - loss: 0.1750 - acc: 0.93 - ETA: 21s - loss: 0.1745 - acc: 0.93 - ETA: 21s - loss: 0.1740 - acc: 0.93 - ETA: 20s - loss: 0.1740 - acc: 0.93 - ETA: 20s - loss: 0.1735 - acc: 0.93 - ETA: 20s - loss: 0.1732 - acc: 0.93 - ETA: 20s - loss: 0.1730 - acc: 0.93 - ETA: 20s - loss: 0.1731 - acc: 0.93 - ETA: 19s - loss: 0.1733 - acc: 0.93 - ETA: 19s - loss: 0.1729 - acc: 0.93 - ETA: 19s - loss: 0.1730 - acc: 0.93 - ETA: 19s - loss: 0.1731 - acc: 0.93 - ETA: 19s - loss: 0.1728 - acc: 0.93 - ETA: 18s - loss: 0.1735 - acc: 0.93 - ETA: 18s - loss: 0.1731 - acc: 0.93 - ETA: 18s - loss: 0.1746 - acc: 0.93 - ETA: 18s - loss: 0.1755 - acc: 0.93 - ETA: 18s - loss: 0.1755 - acc: 0.93 - ETA: 17s - loss: 0.1756 - acc: 0.93 - ETA: 17s - loss: 0.1752 - acc: 0.93 - ETA: 17s - loss: 0.1753 - acc: 0.93 - ETA: 17s - loss: 0.1760 - acc: 0.93 - ETA: 17s - loss: 0.1764 - acc: 0.93 - ETA: 16s - loss: 0.1763 - acc: 0.93 - ETA: 16s - loss: 0.1773 - acc: 0.93 - ETA: 16s - loss: 0.1774 - acc: 0.93 - ETA: 16s - loss: 0.1769 - acc: 0.93 - ETA: 16s - loss: 0.1779 - acc: 0.93 - ETA: 15s - loss: 0.1778 - acc: 0.93 - ETA: 15s - loss: 0.1783 - acc: 0.93 - ETA: 15s - loss: 0.1785 - acc: 0.93 - ETA: 15s - loss: 0.1789 - acc: 0.93 - ETA: 15s - loss: 0.1793 - acc: 0.93 - ETA: 14s - loss: 0.1797 - acc: 0.93 - ETA: 14s - loss: 0.1806 - acc: 0.93 - ETA: 14s - loss: 0.1809 - acc: 0.93 - ETA: 14s - loss: 0.1804 - acc: 0.93 - ETA: 14s - loss: 0.1800 - acc: 0.93 - ETA: 13s - loss: 0.1802 - acc: 0.93 - ETA: 13s - loss: 0.1803 - acc: 0.93 - ETA: 13s - loss: 0.1799 - acc: 0.93 - ETA: 13s - loss: 0.1797 - acc: 0.93 - ETA: 12s - loss: 0.1800 - acc: 0.93 - ETA: 12s - loss: 0.1797 - acc: 0.93 - ETA: 12s - loss: 0.1795 - acc: 0.93 - ETA: 12s - loss: 0.1796 - acc: 0.93 - ETA: 12s - loss: 0.1800 - acc: 0.93 - ETA: 11s - loss: 0.1801 - acc: 0.93 - ETA: 11s - loss: 0.1797 - acc: 0.93 - ETA: 11s - loss: 0.1794 - acc: 0.93 - ETA: 11s - loss: 0.1793 - acc: 0.93 - ETA: 11s - loss: 0.1805 - acc: 0.93 - ETA: 10s - loss: 0.1801 - acc: 0.93 - ETA: 10s - loss: 0.1803 - acc: 0.93 - ETA: 10s - loss: 0.1804 - acc: 0.93 - ETA: 10s - loss: 0.1801 - acc: 0.93 - ETA: 10s - loss: 0.1806 - acc: 0.93 - ETA: 9s - loss: 0.1807 - acc: 0.9339 - ETA: 9s - loss: 0.1807 - acc: 0.934 - ETA: 9s - loss: 0.1810 - acc: 0.933 - ETA: 9s - loss: 0.1815 - acc: 0.933 - ETA: 9s - loss: 0.1814 - acc: 0.933 - ETA: 8s - loss: 0.1817 - acc: 0.933 - ETA: 8s - loss: 0.1821 - acc: 0.933 - ETA: 8s - loss: 0.1824 - acc: 0.933 - ETA: 8s - loss: 0.1825 - acc: 0.933 - ETA: 8s - loss: 0.1827 - acc: 0.933 - ETA: 7s - loss: 0.1829 - acc: 0.933 - ETA: 7s - loss: 0.1826 - acc: 0.933 - ETA: 7s - loss: 0.1828 - acc: 0.933 - ETA: 7s - loss: 0.1829 - acc: 0.933 - ETA: 7s - loss: 0.1826 - acc: 0.933 - ETA: 6s - loss: 0.1826 - acc: 0.933 - ETA: 6s - loss: 0.1829 - acc: 0.933 - ETA: 6s - loss: 0.1827 - acc: 0.933 - ETA: 6s - loss: 0.1821 - acc: 0.933 - ETA: 6s - loss: 0.1826 - acc: 0.933 - ETA: 5s - loss: 0.1825 - acc: 0.933 - ETA: 5s - loss: 0.1821 - acc: 0.933 - ETA: 5s - loss: 0.1822 - acc: 0.933 - ETA: 5s - loss: 0.1822 - acc: 0.933 - ETA: 5s - loss: 0.1826 - acc: 0.933 - ETA: 4s - loss: 0.1825 - acc: 0.933 - ETA: 4s - loss: 0.1825 - acc: 0.932 - ETA: 4s - loss: 0.1831 - acc: 0.932 - ETA: 4s - loss: 0.1835 - acc: 0.932 - ETA: 4s - loss: 0.1838 - acc: 0.932 - ETA: 3s - loss: 0.1838 - acc: 0.932 - ETA: 3s - loss: 0.1839 - acc: 0.932 - ETA: 3s - loss: 0.1841 - acc: 0.932 - ETA: 3s - loss: 0.1847 - acc: 0.932 - ETA: 3s - loss: 0.1849 - acc: 0.932 - ETA: 2s - loss: 0.1851 - acc: 0.931 - ETA: 2s - loss: 0.1850 - acc: 0.931 - ETA: 2s - loss: 0.1852 - acc: 0.931 - ETA: 2s - loss: 0.1849 - acc: 0.931 - ETA: 2s - loss: 0.1850 - acc: 0.931 - ETA: 1s - loss: 0.1853 - acc: 0.931 - ETA: 1s - loss: 0.1850 - acc: 0.931 - ETA: 1s - loss: 0.1848 - acc: 0.931 - ETA: 1s - loss: 0.1847 - acc: 0.931 - ETA: 1s - loss: 0.1847 - acc: 0.931 - ETA: 0s - loss: 0.1847 - acc: 0.931 - ETA: 0s - loss: 0.1846 - acc: 0.931 - ETA: 0s - loss: 0.1844 - acc: 0.931 - ETA: 0s - loss: 0.1845 - acc: 0.931 - ETA: 0s - loss: 0.1849 - acc: 0.931 - 41s 2ms/step - loss: 0.1848 - acc: 0.9316 - val_loss: 0.3431 - val_acc: 0.8704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23833e81710>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_size))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 3\n",
    "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"D:/DataRepository/final_project/Final-Project-IMDB-Reviews/testData.tsv\"\n",
    "\n",
    "# Import the CSV into a pandas DataFrame\n",
    "df_test = pd.read_csv(csv_path, low_memory=False, sep = '\\t')\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.8584793401994173\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11090,  2039],\n",
       "       [ 1410, 10461]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"review\"]=df_test.review.apply(lambda x: clean_text(x))\n",
    "df_test[\"sentiment\"] = df_test[\"id\"].map(lambda x: 1 if int(x.strip('\"').split(\"_\")[1]) >= 5 else 0)\n",
    "y_test = df_test[\"sentiment\"]\n",
    "list_sentences_test = df_test[\"review\"]\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "prediction = model.predict(X_te)\n",
    "y_pred = (prediction > 0.5)\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "print('F1-score: {0}'.format(f1_score(y_pred, y_test)))\n",
    "print('Confusion matrix:')\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23846854d30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
